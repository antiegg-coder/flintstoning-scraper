import os
import json
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import pandas as pd
import requests
from bs4 import BeautifulSoup
from openai import OpenAI
import random
import time

# =========================================================
# 1. ì„¤ì • ë° ì¸ì¦
# =========================================================
try:
    print("--- [Recruit Sender] ì±„ìš© ê³µê³  í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ ---")
    
    if 'GOOGLE_CREDENTIALS' not in os.environ:
        raise Exception("í™˜ê²½ë³€ìˆ˜ GOOGLE_CREDENTIALSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    creds_dict = json.loads(os.environ['GOOGLE_CREDENTIALS'])
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)

    spreadsheet = client.open('í”Œë¦°íŠ¸ìŠ¤í† ë‹ ì†Œì¬ DB')
    
    # GID 1818966683 ê¸°ë°˜ ì‹œíŠ¸ ì„ íƒ
    TARGET_GID = 1818966683
    sheet = next((s for s in spreadsheet.worksheets() if s.id == TARGET_GID), None)
    
    if not sheet:
        raise Exception(f"GIDê°€ {TARGET_GID}ì¸ ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    data = sheet.get_all_values()
    headers = [h.strip() for h in data[0]]
    df = pd.DataFrame(data[1:], columns=headers)

    # ì»¬ëŸ¼ ì„¤ì • (ì‹œíŠ¸ì˜ ì‹¤ì œ í—¤ë”ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤)
    COL_STATUS = 'status'
    COL_IDENTITY = 'identity_match'
    COL_TITLE = 'title'     
    COL_URL = 'url'         
    COL_LOCATION = 'location' 
    COL_EXPERIENCE = 'experience'

    target_rows = df[df[COL_STATUS].str.strip().str.lower() == 'archived']

    if target_rows.empty:
        print("â„¹ï¸ 'archived' ìƒíƒœì˜ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    identity_col_idx = headers.index(COL_IDENTITY) + 1
    status_col_idx = headers.index(COL_STATUS) + 1
    client_openai = OpenAI(api_key=os.environ['OPENAI_API_KEY'])
    webhook_url = os.environ['SLACK_WEBHOOK_URL']
    
    session = requests.Session()

    # =========================================================
    # 2. ë©”ì¸ ë£¨í”„
    # =========================================================
    for index, row in target_rows.iterrows():
        update_row_index = int(index) + 2
        raw_title = row[COL_TITLE]
        target_url = row[COL_URL]
        
        # [ìˆ˜ì •] ì§€ì—­ ë° ê²½ë ¥ ì •ë³´ë¥¼ ì‹œíŠ¸ì—ì„œ ì§ì ‘ ì°¸ì¡°
        sheet_location = row.get(COL_LOCATION, "ì •ë³´ ì—†ìŒ").strip() or "ì •ë³´ ì—†ìŒ"
        sheet_experience = row.get(COL_EXPERIENCE, "ê²½ë ¥ ë¬´ê´€").strip() or "ê²½ë ¥ ë¬´ê´€"
        
        print(f"\nğŸ” {update_row_index}í–‰ ê²€í†  ì¤‘: {raw_title}")

        try:
            # 3. [403 Forbidden í•´ê²°] ê°•ë ¥í•œ ë¸Œë¼ìš°ì € ìœ„ì¥ ë° ëœë¤ ëŒ€ê¸°
            headers_ua = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
                'Referer': 'https://www.google.com/',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }

            time.sleep(random.uniform(2.5, 4.5))
            resp = session.get(target_url, headers=headers_ua, timeout=15)
            resp.raise_for_status()
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            text_content = " ".join([p.get_text().strip() for p in soup.find_all(['p', 'h2', 'h3', 'li', 'span', 'div']) if len(p.get_text().strip()) > 10])
            truncated_text = text_content[:3800]

            # 4. [ì í•©ì„± íŒë‹¨] ì±„ìš© ê³µê³  ì—¬ë¶€ ë° ì—ë””íŒ… ì§ë¬´ í•„í„°ë§
            identity_prompt = f"""
            ë‹¹ì‹ ì€ ì—ë””í„° ê³µë™ì²´ì˜ ì»¤ë¦¬ì–´ íë ˆì´í„°ì…ë‹ˆë‹¤. ì•„ë˜ ê¸€ì´ ì—ë””í„°ê°€ ì§€ì›í•  ë§Œí•œ 'ì •ì‹ ì±„ìš© ê³µê³ 'ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.
            [ê¸°ì¤€] ì½˜í…ì¸  ì—ë””í„°, ê¸°íšì, ë‰´ìŠ¤ë ˆí„° ì‘ê°€ ë“± 'í…ìŠ¤íŠ¸/ì½˜í…ì¸ ' ì¤‘ì‹¬ ì§ë¬´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            [ë‚´ìš©] {truncated_text}
            ì¶œë ¥ í¬ë§·(JSON): {{"is_appropriate": true/false}}
            """
            check_res = client_openai.chat.completions.create(
                model="gpt-4o-mini",
                response_format={ "type": "json_object" },
                messages=[{"role": "user", "content": identity_prompt}]
            )
            judgment = json.loads(check_res.choices[0].message.content)
            
            time.sleep(1)
            sheet.update_cell(update_row_index, identity_col_idx, str(judgment['is_appropriate']).upper())

            if not judgment['is_appropriate']:
                print(f"âš ï¸ ë¶€ì í•© íŒì •ìœ¼ë¡œ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                continue

            # 5. [ìŠ¬ë™ ìƒì„±] ì´ë¯¸ì§€ UI ê¸°ë°˜ ë°ì´í„° ì¶”ì¶œ (ì§€ì—­/ê²½ë ¥ ì¶”ë¡  ì œì™¸)
            summary_prompt = f"""
            ë™ë£Œ ì—ë””í„°ë“¤ì„ ìœ„í•´ ì±„ìš© ê³µê³  ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. 
            [ì§€ì¹¨]:
            1. company_job: "[íšŒì‚¬ëª…] ì§ë¬´ëª…" í˜•ì‹ì˜ ì œëª©ì„ ë³¸ë¬¸ì—ì„œ ì°¾ì•„ ì‘ì„±í•˜ì„¸ìš”.
            2. roles: ì£¼ìš” ì—­í•  3ê°€ì§€.
            3. requirements: ìš”êµ¬ ì—­ëŸ‰ 3ê°€ì§€.
            4. preferences: ìš°ëŒ€ ì‚¬í•­ 2~3ê°€ì§€.
            5. recommendations: ì—ë””í„°ì—ê²Œ ì¶”ì²œí•˜ëŠ” ì´ìœ  3ê°€ì§€ (ëë§ºìŒ: "~í•œ ë¶„", 'ì—ë””í„°' ë‹¨ì–´ ì‚¬ìš© ê¸ˆì§€).

            [ë‚´ìš©] {truncated_text}
            ì¶œë ¥ í¬ë§·(JSON): {{"company_job": "", "roles": [], "requirements": [], "preferences": [], "recommendations": []}}
            """
            summary_res = client_openai.chat.completions.create(
                model="gpt-4o-mini",
                response_format={ "type": "json_object" },
                messages=[{"role": "user", "content": summary_prompt}]
            )
            gpt_res = json.loads(summary_res.choices[0].message.content)
            
            # 6. ìŠ¬ë™ ì „ì†¡ (ì´ë¯¸ì§€ UI ì¬í˜„ + ì‹œíŠ¸ ë°ì´í„° ë°˜ì˜)
            blocks = [
                {"type": "section", "text": {"type": "mrkdwn", "text": "*ì˜¤ëŠ˜ ì˜¬ë¼ì˜¨ ì±„ìš© ê³µê³ *"}},
                {"type": "section", "text": {"type": "mrkdwn", "text": f"*{gpt_res.get('company_job', raw_title)}*"}},
                {
                    "type": "section",
                    "fields": [
                        {"type": "mrkdwn", "text": f"*ì§€ì—­*\n{sheet_location}"},
                        {"type": "mrkdwn", "text": f"*ê²½ë ¥*\n{sheet_experience}"}
                    ]
                },
                {"type": "divider"},
                {"type": "section", "text": {"type": "mrkdwn", "text": "ğŸ“Œ *ì£¼ìš” ì—­í• *\n" + "\n".join([f"â€¢ {r}" for r in gpt_res.get('roles', [])])}},
                {"type": "section", "text": {"type": "mrkdwn", "text": "ğŸ“Œ *ìš”êµ¬ ì—­ëŸ‰*\n" + "\n".join([f"â€¢ {req}" for req in gpt_res.get('requirements', [])])}},
                {"type": "section", "text": {"type": "mrkdwn", "text": "ğŸ“Œ *ìš°ëŒ€ ì‚¬í•­*\n" + "\n".join([f"â€¢ {p}" for p in gpt_res.get('preferences', [])])}},
                {"type": "section", "text": {"type": "mrkdwn", "text": "ğŸ“Œ *ì´ëŸ° ë¶„ê»˜ ì¶”ì²œí•´ìš”*\n" + "\n".join([f"â€¢ {rec}" for rec in gpt_res.get('recommendations', [])])}},
                {"type": "divider"},
                {"type": "actions", "elements": [{"type": "button", "text": {"type": "plain_text", "text": "ìƒì„¸ ê³µê³  ë³´ëŸ¬ê°€ê¸°", "emoji": True}, "style": "primary", "url": target_url}]}
            ]
            
            requests.post(webhook_url, json={"blocks": blocks})
            
            time.sleep(1)
            sheet.update_cell(update_row_index, status_col_idx, 'published')
            print(f"âœ… ì „ì†¡ ì„±ê³µ: {raw_title}")
            break 

        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            continue

except Exception as e:
    print(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
finally:
    print("--- ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ---")
