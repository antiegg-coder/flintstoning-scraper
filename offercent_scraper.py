import os, time, json, re
import gspread
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# [ì„¤ì •] ì´ íŒŒì¼ ì „ìš© ì •ë³´ (ê¸°ì¡´ê³¼ ë™ì¼)
CONFIG = {
    "name": "ì˜¤í¼ì„¼íŠ¸",
    "url": "https://offercent.co.kr/company-list?jobCategories=0040002%2C0170004",
    "gid": "639559541" # ì˜¤í¼ì„¼íŠ¸ íƒ­ GID
}

# [ê³µí†µ] ì‹œíŠ¸ ì—°ê²° (ê¸°ì¡´ê³¼ ë™ì¼)
def get_worksheet():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds_dict = json.loads(os.environ['GOOGLE_CREDENTIALS'])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    spreadsheet = client.open_by_url("https://docs.google.com/spreadsheets/d/1nKPVCZ6zAOfpqCjV6WfjkzCI55FA9r2yvi9XL3iIneo/edit")
    
    sheet = next((s for s in spreadsheet.worksheets() if str(s.id) == CONFIG["gid"]), None)
    if not sheet: raise Exception(f"{CONFIG['gid']} ì‹œíŠ¸ë¥¼ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return sheet

# [ê³µí†µ] ë¸Œë¼ìš°ì € ì‹¤í–‰ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
def get_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    
    # [í•µì‹¬ ìˆ˜ì •] í™”ë©´ í¬ê¸°ë¥¼ PC ê·œê²©(1920x1080)ìœ¼ë¡œ ê°•ì œ ì„¤ì •í•©ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•˜ë©´ ì‚¬ì§„ ì†ì˜ ëª¨ë°”ì¼ í™”ë©´ì´ ì•„ë‹Œ, ìš°ë¦¬ê°€ ì²˜ìŒì— ë³¸ PC í™”ë©´ì´ ëœ¹ë‹ˆë‹¤.
    options.add_argument("--window-size=1920,1080")
    
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    options.add_argument("--disable-blink-features=AutomationControlled")
    
    driver = webdriver.Chrome(options=options)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
    })
    return driver
    
# [ì „ìš©] ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ (ìŠ¤í¬ë¦°ìƒ· ì¶”ê°€)
def scrape_projects():
    driver = get_driver()
    new_data = []
    today = datetime.now().strftime("%Y-%m-%d")
    urls_check = set()
    
    # ë””ë²„ê¹…ìš© ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ê²½ë¡œ
    output_dir = "screenshots"
    os.makedirs(output_dir, exist_ok=True)

    try:
        driver.get(CONFIG["url"])
        
        # 1. ê³µê³  ë°ì´í„° ë¡œë”© ëŒ€ê¸° (ìµœëŒ€ 20ì´ˆ)
        wait = WebDriverWait(driver, 20)
        try:
            print("â³ ëª¨ë°”ì¼ ë ˆì´ì•„ì›ƒ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘...")
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span[data-variant="body-02"]')))
            time.sleep(5) # ë Œë”ë§ ì•ˆì •ì„ ìœ„í•œ ì¶”ê°€ ì‹œê°„
        except:
            print("âš ï¸ ë¡œë”© ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ í™”ë©´ì—ì„œ ìˆ˜ì§‘ì„ ì‹œë„í•©ë‹ˆë‹¤.")

        # ì§„ë‹¨ìš© ìŠ¤í¬ë¦°ìƒ· ì°ê¸°
        driver.save_screenshot(os.path.join(output_dir, f"offercent_check_{today}.png"))

        # 2. ìŠ¤í¬ë¡¤í•˜ë©° ë°ì´í„° ìˆ˜ì§‘ (ìµœëŒ€ 10íšŒ)
        for scroll_idx in range(10):
            # í•µì‹¬ íƒ€ê²Ÿ: íšŒì‚¬ëª…ê³¼ ì œëª©ì´ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì†ì„±
            elements = driver.find_elements(By.CSS_SELECTOR, 'span[data-variant="body-02"]')
            
            # ìŠ¤í¬ë¦°ìƒ· êµ¬ì¡° ë¶„ì„ ê²°ê³¼: [íšŒì‚¬ëª…, ì œëª©, íšŒì‚¬ëª…, ì œëª©...] ìˆœì„œë¡œ ë°°ì¹˜ë¨
            # 2ê°œì”© ì§ì„ ì§€ì–´ ì²˜ë¦¬ (Step 2)
            for i in range(0, len(elements) - 1, 2):
                try:
                    company_el = elements[i]
                    title_el = elements[i+1]
                    
                    company_txt = company_el.text.strip()
                    title_txt = title_el.text.strip()

                    # ë°ì´í„° ì •ì œ: ë‚ ì§œ ì •ë³´ê°€ ì œëª©ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ê²ƒ ë°©ì§€
                    if any(x in title_txt for x in ["ì „", "ê°œì›”", "ì¼", "ì£¼"]) or len(title_txt) < 2:
                        continue
                    
                    # ì œëª© ë°”ë¡œ ìœ„ì˜ ë¶€ëª¨ 'a' íƒœê·¸ì—ì„œ ë§í¬ ì¶”ì¶œ
                    # ëª¨ë°”ì¼ êµ¬ì¡°ìƒ ì œëª©ì„ ê°ì‹¸ëŠ” ê°€ì¥ ê°€ê¹Œìš´ ë§í¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                    try:
                        href = title_el.find_element(By.XPATH, "./ancestor::a").get_attribute("href")
                    except:
                        href = CONFIG["url"]

                    # ì¤‘ë³µ ì²´í¬ ë° ì €ì¥
                    data_id = f"{href}_{title_txt}"
                    if data_id not in urls_check:
                        new_data.append({
                            'company': company_txt,
                            'title': title_txt,
                            'url': href,
                            'scraped_at': today
                        })
                        urls_check.add(data_id)
                except:
                    continue
            
            # ë‹¤ìŒ ê³µê³ ë¥¼ ìœ„í•´ ìŠ¤í¬ë¡¤ ë‹¤ìš´
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3)
            print(f"ğŸ”„ ìŠ¤í¬ë¡¤ {scroll_idx + 1}íšŒ ì™„ë£Œ (í˜„ì¬ê¹Œì§€ ë°œê²¬: {len(new_data)}ê±´)")

    except Exception as e:
        print(f"âŒ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally: 
        driver.quit()
    
    print(f"ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ì„±ê³µ: {len(new_data)}ê±´")
    return new_data
    
# [ê³µí†µ] ì‹œíŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸ (ê¸°ì¡´ê³¼ ë™ì¼)
def update_sheet(ws, data):
    if not data: 
        print(f"[{CONFIG['name']}] ìƒˆë¡œ ìˆ˜ì§‘ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_v = ws.get_all_values()
    headers = all_v[0] if all_v else ['company', 'title', 'url', 'scraped_at', 'status']
    
    col_map = {name: i for i, name in enumerate(headers)}
    existing_urls = {row[col_map['url']] for row in all_v[1:] if len(row) > col_map['url']}
    
    rows_to_append = []
    for item in data:
        if item['url'] in existing_urls: continue
        
        row = [''] * len(headers)
        for k, v in item.items():
            if k in col_map: row[col_map[k]] = v
        
        if 'status' in col_map: row[col_map['status']] = 'new'
        
        rows_to_append.append(row)
    
    if rows_to_append:
        ws.append_rows(rows_to_append)
        print(f"ğŸ’¾ {CONFIG['name']} ì‹ ê·œ ê³µê³  {len(rows_to_append)}ê±´ ì €ì¥ ì™„ë£Œ")
    else:
        print(f"[{CONFIG['name']}] ì‹œíŠ¸ì— ì´ë¯¸ ëª¨ë‘ ë°˜ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ ì‹¤í–‰ë¶€ (ê¸°ì¡´ê³¼ ë™ì¼)
if __name__ == "__main__":
    try:
        ws = get_worksheet()
        data = scrape_projects()
        update_sheet(ws, data)
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
