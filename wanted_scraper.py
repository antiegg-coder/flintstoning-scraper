import time
import re
import os
import json
import gspread
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

# ì…€ë ˆë‹ˆì›€ ê´€ë ¨
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
# from selenium.webdriver.support.ui import WebDriverWait # í˜„ì¬ ë¯¸ì‚¬ìš©ì´ë¼ ì£¼ì„ì²˜ë¦¬
# from selenium.webdriver.support import expected_conditions as EC # í˜„ì¬ ë¯¸ì‚¬ìš©ì´ë¼ ì£¼ì„ì²˜ë¦¬

# 1. ì„¤ì •
SHEET_URL = "https://docs.google.com/spreadsheets/d/1nKPVCZ6zAOfpqCjV6WfjkzCI55FA9r2yvi9XL3iIneo/edit"

# â–¼ ì›í‹°ë“œ íƒ­ GID (í™•ì¸ í•„ìˆ˜)
TARGET_GID = 639559541
SCRAPE_URL = "https://www.wanted.co.kr/wdlist/523/1635?country=kr&job_sort=job.popularity_order&years=-1&locations=all"

def get_google_sheet():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds_dict = json.loads(os.environ['GOOGLE_CREDENTIALS'])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    
    spreadsheet = client.open_by_url(SHEET_URL)
    worksheet = None
    
    for sheet in spreadsheet.worksheets():
        if str(sheet.id) == str(TARGET_GID):
            worksheet = sheet
            break
            
    if worksheet is None:
        raise Exception(f"GIDê°€ {TARGET_GID}ì¸ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ“‚ ì—°ê²°ëœ ì‹œíŠ¸: {worksheet.title}")
    return worksheet

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    # options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")
    
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def get_projects():
    driver = get_driver()
    new_data = []
    today = datetime.now().strftime("%Y-%m-%d")

    try:
        print("ğŸŒ ì›í‹°ë“œ(Wanted) ì ‘ì† ì¤‘...")
        driver.get(SCRAPE_URL)
        
        # í™”ë©´ ë¡œë”© ëŒ€ê¸°
        time.sleep(5)
        
        # ìŠ¤í¬ë¡¤ì„ ì‚´ì§ ë‚´ë ¤ì„œ ë°ì´í„°ë¥¼ ë” ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
        driver.execute_script("window.scrollTo(0, 1000);")
        time.sleep(3)
        
        # ëª¨ë“  ë§í¬(a íƒœê·¸) ìˆ˜ì§‘
        elements = driver.find_elements(By.TAG_NAME, "a")
        print(f"ğŸ” í˜ì´ì§€ ë‚´ ì „ì²´ ë§í¬ ìˆ˜: {len(elements)}ê°œ")

        for elem in elements:
            try:
                full_url = elem.get_attribute("href")
                
                # ì›í‹°ë“œ ì±„ìš© ê³µê³  ë§í¬ íŒ¨í„´: /wd/ìˆ«ì
                if not full_url or "/wd/" not in full_url:
                    continue
                
                # í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                raw_text = elem.text.strip()
                if not raw_text: continue

                # [ìˆ˜ì •ëœ ì œëª©/íšŒì‚¬ëª… ì¶”ì¶œ ë¡œì§]
                lines = raw_text.split('\n')
                
                # í•„í„°ë§: ë³´ìƒê¸ˆ, ì‘ë‹µë¥  ë“± ë¶ˆí•„ìš”í•œ ì •ë³´ê°€ ì„ì¸ ì¤„ ì œê±°
                cleaned_lines = []
                for line in lines:
                    text = line.strip()
                    if not text: continue
                    
                    # 1. 'í•©ê²©ë³´ìƒê¸ˆ'ì´ë‚˜ 'ë§Œì›' ê°™ì€ ëˆ ê´€ë ¨ ë‹¨ì–´ ì œê±°
                    if "í•©ê²©ë³´ìƒê¸ˆ" in text or "ë³´ìƒê¸ˆ" in text:
                        continue
                    # 2. ìˆ«ìë¡œë§Œ ë˜ì–´ìˆê±°ë‚˜ 'ì›'ìœ¼ë¡œ ëë‚˜ëŠ” ê¸ˆì•¡ ì œê±° (ì˜ˆ: 1,000,000ì›)
                    if text.endswith("ì›") and any(c.isdigit() for c in text):
                        continue
                    # 3. 'ì‘ë‹µë¥  ë†’ìŒ' ê°™ì€ ë±ƒì§€ ì œê±°
                    if "ì‘ë‹µë¥ " in text or "ì…ì‚¬ì¶•í•˜ê¸ˆ" in text or "ì§€ì—­" in text: # ì§€ì—­ ì •ë³´ë„ í•„í„°ë§ì— ì¶”ê°€
                        continue
                        
                    cleaned_lines.append(text)
                
                if not cleaned_lines:
                    continue
                    
                # ---- [ë³€ê²½ì  1] íšŒì‚¬ëª… ì¶”ì¶œ ë¡œì§ ì¶”ê°€ ----
                # í•„í„°ë§ í›„ ë‚¨ì€ ì¤„ ì¤‘ ì²« ë²ˆì§¸ê°€ ì œëª©, ë‘ ë²ˆì§¸ê°€ íšŒì‚¬ëª…ì´ë¼ê³  ê°€ì •
                title = cleaned_lines[0]
                company = "" # ê¸°ë³¸ê°’ ë¹„ì›Œë‘ 

                # ì •ì œëœ ì¤„ì´ 2ì¤„ ì´ìƒ ë‚¨ì•„ìˆë‹¤ë©´, ë‘ ë²ˆì§¸ ì¤„ì„ íšŒì‚¬ëª…ìœ¼ë¡œ ê°„ì£¼
                if len(cleaned_lines) >= 2:
                    company = cleaned_lines[1]
                # -----------------------------------------
                
                idx_match = re.search(r'/wd/(\d+)', full_url)
                # ì œëª©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì´ìƒí•œ ë°ì´í„°ì¼ ìˆ˜ ìˆìŒ (ê¸¸ì´ ì¡°ê±´ ì•½ê°„ ì™„í™”)
                if len(title) > 1 and idx_match:
                    
                    if not any(d['url'] == full_url for d in new_data):
                        new_data.append({
                            'title': title,
                            'company': company, # ë°ì´í„°ì— íšŒì‚¬ëª… ì¶”ê°€
                            'url': full_url,
                            'scraped_at': today
                        })
            except Exception as e_inner:
                 # ê°œë³„ ìš”ì†Œ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ë‹¤ìŒ ìš”ì†Œë¡œ ì§„í–‰
                 # print(f"ê°œë³„ ìš”ì†Œ ì²˜ë¦¬ ì—ëŸ¬: {e_inner}")
                 continue
                
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        driver.quit()
            
    print(f"ğŸ¯ ìˆ˜ì§‘ëœ ê³µê³ : {len(new_data)}ê°œ")
    # í™•ì¸ì„ ìœ„í•´ ìƒìœ„ 3ê°œë§Œ ì¶œë ¥í•´ë´„
    # for d in new_data[:3]:
    #     print(f"- [{d['company']}] {d['title']}")
        
    return new_data

def update_sheet(worksheet, data):
    all_values = worksheet.get_all_values()
    
    if not all_values:
        # ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ í—¤ë”ë¶€í„° ë§Œë“­ë‹ˆë‹¤.
        headers = ['title', 'company', 'url', 'scraped_at', 'status']
        worksheet.append_row(headers)
        all_values = [headers] # ì•„ë˜ ë¡œì§ì„ ìœ„í•´ ì¶”ê°€
        print("â„¹ï¸ ë¹ˆ ì‹œíŠ¸ ê°ì§€: í—¤ë” í–‰ì„ ìƒˆë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.")
    else:
        headers = all_values[0]

    try:
        # ---- [ë³€ê²½ì  2] company ì¸ë±ìŠ¤ ì°¾ê¸° ì¶”ê°€ ----
        idx_title = headers.index('title')
        idx_company = headers.index('company') # í•„ìˆ˜! ì‹œíŠ¸ì— ì´ ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•¨
        idx_url = headers.index('url')
        idx_scraped_at = headers.index('scraped_at')
        idx_status = headers.index('status')
        # -------------------------------------------
    except ValueError as e:
        missing_col = str(e).split("'")[1]
        print(f"â›” í—¤ë” ì˜¤ë¥˜: ì‹œíŠ¸ 1í–‰ì— '{missing_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("title, company, url, scraped_at, status í—¤ë”ê°€ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    existing_urls = set()
    # ë°ì´í„°ê°€ ìˆëŠ” 2í–‰ë¶€í„° URL ìˆ˜ì§‘
    if len(all_values) > 1:
        for row in all_values[1:]:
            # í–‰ì˜ ê¸¸ì´ê°€ idx_urlë³´ë‹¤ ì§§ì„ ê²½ìš° ëŒ€ë¹„
            if len(row) > idx_url:
                existing_urls.add(row[idx_url])

    rows_to_append = []
    # êµ¬ê¸€ ì‹œíŠ¸ API ìš”êµ¬ì‚¬í•­ì— ë§ì¶° ë¹ˆ ì…€ë¡œ ì±„ì›Œì§„ ê¸°ë³¸ í–‰ ìƒì„±
    empty_row_structure = [''] * len(headers)

    for item in data:
        if item['url'] in existing_urls:
            continue
            
        new_row = empty_row_structure.copy()
        new_row[idx_title] = item['title']
        new_row[idx_company] = item['company'] # íšŒì‚¬ëª… ë§¤í•‘
        new_row[idx_url] = item['url']
        new_row[idx_scraped_at] = item['scraped_at']
        new_row[idx_status] = 'archived'
        rows_to_append.append(new_row)

    if rows_to_append:
        # í•œ ë²ˆì— ì—¬ëŸ¬ í–‰ ì¶”ê°€ (API í˜¸ì¶œ ìµœì†Œí™”)
        worksheet.append_rows(rows_to_append)
        print(f"ğŸ’¾ {len(rows_to_append)}ê°œ ì‹ ê·œ ê³µê³  ì €ì¥ ì™„ë£Œ!")
    else:
        print("â„¹ï¸ ì €ì¥í•  ìƒˆë¡œìš´ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    try:
        sheet = get_google_sheet()
        projects = get_projects()
        update_sheet(sheet, projects)
    except Exception as e:
        print(f"ğŸš¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
