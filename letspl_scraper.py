import time
import re
import os
import json
import gspread
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials

# ì…€ë ˆë‹ˆì›€ ê´€ë ¨
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 1. ì„¤ì •
SHEET_URL = "https://docs.google.com/spreadsheets/d/1nKPVCZ6zAOfpqCjV6WfjkzCI55FA9r2yvi9XL3iIneo/edit"
TARGET_GID = 981623942  # ì‹œíŠ¸ íƒ­ GID
# [ìˆ˜ì •ë¨] ë ›í”Œ(Letspl) ê²€ìƒ‰ ê²°ê³¼ URL
SCRAPE_URL = "https://letspl.me/project?location=KR00&type=00&recruitingType=all&jobD=0207&skill=&interest=&keyword="

def get_google_sheet():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds_dict = json.loads(os.environ['GOOGLE_CREDENTIALS'])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    
    spreadsheet = client.open_by_url(SHEET_URL)
    worksheet = None
    
    for sheet in spreadsheet.worksheets():
        if str(sheet.id) == str(TARGET_GID):
            worksheet = sheet
            break
            
    if worksheet is None:
        raise Exception(f"GIDê°€ {TARGET_GID}ì¸ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ“‚ ì—°ê²°ëœ ì‹œíŠ¸: {worksheet.title}")
    return worksheet

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    chrome_options.add_argument(f"user-agent={user_agent}")
    
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def get_projects():
    driver = get_driver()
    new_data = []
    today = datetime.now().strftime("%Y-%m-%d")

    try:
        print("ğŸŒ Letspl ì ‘ì† ì¤‘...")
        driver.get(SCRAPE_URL)
        
        # [ìˆ˜ì •ë¨] ìŠ¤ë§ˆíŠ¸ ëŒ€ê¸°: í”„ë¡œì íŠ¸ ë¦¬ìŠ¤íŠ¸ê°€ ëœ° ë•Œê¹Œì§€ ìµœëŒ€ 15ì´ˆ ëŒ€ê¸°
        # ë ›í”Œì€ ë§í¬(a) íƒœê·¸ì˜ hrefê°€ '/project/'ë¡œ ì‹œì‘í•¨
        wait = WebDriverWait(driver, 15)
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a[href^='/project/']")))
        
        # ì•½ê°„ì˜ ì¶”ê°€ ë¡œë”© ëŒ€ê¸° (ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ë Œë”ë§)
        time.sleep(3)
        
        # [ìˆ˜ì •ë¨] CSS Selectorë¡œ í”„ë¡œì íŠ¸ ë§í¬ë§Œ ì •í™•íˆ íƒ€ê²ŸíŒ…
        # href ì†ì„±ì´ '/project/'ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  a íƒœê·¸ ìˆ˜ì§‘
        elements = driver.find_elements(By.CSS_SELECTOR, "a[href^='/project/']")
        print(f"ğŸ” ë°œê²¬ëœ í”„ë¡œì íŠ¸ ë§í¬ ìˆ˜: {len(elements)}ê°œ")

        for elem in elements:
            try:
                full_url = elem.get_attribute("href")
                
                # ----------------------------------------------------
                # [í•„í„°ë§ ë¡œì§]
                # 1. ì‹¤ì œ í”„ë¡œì íŠ¸ ìƒì„¸ ë§í¬ì¸ì§€ í™•ì¸ (ìˆ«ì IDê°€ í¬í•¨ë˜ì–´ì•¼ í•¨)
                # ì˜ˆ: https://letspl.me/project/1234/ì œëª© -> OK
                # ì˜ˆ: https://letspl.me/project -> NO (ìƒë‹¨ ë©”ë‰´ë°” ë“±)
                if not re.search(r'/project/\d+', full_url):
                    continue
                
                # 2. ì œëª© ì¶”ì¶œ
                # ë ›í”Œì€ a íƒœê·¸ ì•ˆì— í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ ê°œ(ìƒíƒœ, ì¸ì› ë“±) ì„ì—¬ ìˆìŒ.
                # ë³´í†µ ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ë‚˜, ì¤„ë°”ê¿ˆìœ¼ë¡œ ë‚˜ëˆ´ì„ ë•Œ í•µì‹¬ ë¬¸êµ¬ê°€ ì œëª©ì„.
                raw_text = elem.text.strip()
                if not raw_text:
                    continue

                lines = raw_text.split('\n')
                # ë¶ˆí•„ìš”í•œ íƒœê·¸ í…ìŠ¤íŠ¸ ì œê±° ('ëª¨ì§‘ì¤‘', 'í”„ë¡œì íŠ¸', 'ìƒˆë¡œìš´' ë“±)
                cleaned_lines = [
                    line.strip() for line in lines 
                    if len(line.strip()) > 2  # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œì™¸
                    and "ëª¨ì§‘" not in line
                    and "ìŠ¤í¬ë©" not in line
                ]
                
                if cleaned_lines:
                     # ë³´í†µ ì²« ë²ˆì§¸ë‚˜ ë‘ ë²ˆì§¸ ì˜ë¯¸ ìˆëŠ” ì¤„ì´ ì œëª©ì¼ í™•ë¥ ì´ ë†’ìŒ
                     # ì—¬ê¸°ì„œëŠ” ê°€ì¥ ê¸´ ì¤„ì„ ì œëª©ìœ¼ë¡œ ì±„íƒ (ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë˜ ì•ˆì „ì¥ì¹˜)
                    title = max(cleaned_lines, key=len)
                else:
                    title = raw_text
                # ----------------------------------------------------

                # ì¤‘ë³µ ì²´í¬ ë° ë°ì´í„° ì¶”ê°€
                if len(title) > 2:
                    if not any(d['url'] == full_url for d in new_data):
                        new_data.append({
                            'title': title,
                            'url': full_url,
                            'created_at': today
                        })
            except Exception as e:
                # ê°œë³„ ìš”ì†Œ ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                continue
                
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        driver.quit()
            
    print(f"ğŸ¯ ì •ì œëœ ê²Œì‹œë¬¼: {len(new_data)}ê°œ")
    return new_data

def update_sheet(worksheet, data):
    # (ì´ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
    all_values = worksheet.get_all_values()
    
    if not all_values:
        headers = []
    else:
        headers = all_values[0]

    try:
        idx_title = headers.index('title')
        idx_url = headers.index('url')
        idx_created_at = headers.index('created_at')
        idx_status = headers.index('status')
    except ValueError:
        print("â›” í—¤ë” ì˜¤ë¥˜: ì‹œíŠ¸ 1í–‰ì— title, url, created_at, status ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        return

    existing_urls = set()
    for row in all_values[1:]:
        if len(row) > idx_url:
            existing_urls.add(row[idx_url])

    rows_to_append = []
    for item in data:
        if item['url'] in existing_urls:
            continue
            
        new_row = [''] * len(headers)
        new_row[idx_title] = item['title']
        new_row[idx_url] = item['url']
        new_row[idx_created_at] = item['created_at']
        new_row[idx_status] = 'archived'
        
        rows_to_append.append(new_row)

    if rows_to_append:
        worksheet.append_rows(rows_to_append)
        print(f"ğŸ’¾ {len(rows_to_append)}ê°œ ì €ì¥ ì™„ë£Œ!")
    else:
        print("â„¹ï¸ ìƒˆë¡œìš´ ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    try:
        sheet = get_google_sheet()
        projects = get_projects()
        update_sheet(sheet, projects)
    except Exception as e:
        print(f"ğŸš¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
